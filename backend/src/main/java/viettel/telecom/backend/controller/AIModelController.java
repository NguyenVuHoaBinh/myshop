package viettel.telecom.backend.controller;

import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import viettel.telecom.backend.entity.promptbuilder.Template;
import viettel.telecom.backend.service.llm.LLMService;
import viettel.telecom.backend.service.promptbuilder.TemplateService;

import java.util.List;
import java.util.Map;

@RestController
@RequestMapping("/api/v1/ai")
public class AIModelController {

    private final LLMService llmService;
    private final TemplateService templateService;

    @Autowired
    public AIModelController(LLMService llmService, TemplateService templateService) {
        this.llmService = llmService;
        this.templateService = templateService;
    }

    @PostMapping("/generate")
    public ResponseEntity<Map<String, Object>> generateResponse(
            @RequestParam(required = false) String modelType,
            @RequestParam String templateId,
            @RequestBody Map<String, Object> userInput) {

        String systemPrompt = templateService.getTemplate(templateId).getSystemPrompt();
        String userMessage = (String) userInput.get("message");
        Map<String, Object> llmconfig = (Map<String, Object>) userInput.getOrDefault("llmconfig", Map.of());
        if (modelType == null && llmconfig.get("aiModel") != null) {
            modelType = llmconfig.get("aiModel").toString();
        }
        Map<String, Object> response = llmService.processRequest(modelType, systemPrompt, userMessage, llmconfig);
        return ResponseEntity.ok(response);
    }

    @PostMapping("/preview")
    public ResponseEntity<Map<String, Object>> generatePreview(@RequestBody Map<String, Object> request) {
        try {
            String modelType = (String) request.get("modelType");
            String templateId = (String) request.get("templateId");
            String message = (String) request.get("message");
            Map<String, Object> llmconfig = (Map<String, Object>) request.getOrDefault("llmconfig", Map.of());
            if (modelType == null && llmconfig.get("aiModel") != null) {
                modelType = llmconfig.get("aiModel").toString();
            }
            Template template = templateService.getTemplate(templateId);
            String systemPrompt = template.getSystemPrompt();
            String combinedPrompt = systemPrompt + "\n" + message;
            Map<String, Object> response = llmService.processRequest(modelType, combinedPrompt, message, llmconfig);

            // Attempt to extract the AI response
            String aiResponse = null;
            if (response != null && response.get("choices") != null) {
                List<Map<String, Object>> choices = (List<Map<String, Object>>) response.get("choices");
                if (choices != null && !choices.isEmpty()) {
                    Map<String, Object> messageContent = (Map<String, Object>) choices.get(0).get("message");
                    if (messageContent != null) {
                        aiResponse = (String) messageContent.get("content");
                    }
                }
            }
            if (aiResponse == null && response.get("content") != null) {
                aiResponse = response.get("content").toString();
            }
            if (aiResponse == null) {
                aiResponse = "No response generated by the AI model.";
            }
            Map<String, Object> result = Map.of(
                    "combinedPrompt", combinedPrompt,
                    "response", aiResponse
            );
            return ResponseEntity.ok(result);
        } catch (Exception e) {
            e.printStackTrace();
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                    .body(Map.of("error", e.getMessage()));
        }
    }
}
