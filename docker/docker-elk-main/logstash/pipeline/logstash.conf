input {
    # Filebeat input for handling logs sent by Filebeat
    beats {
        port => 5044
		codec => "json"
    }

    # TCP input for handling logs sent directly over TCP
    tcp {
        port => 50000
        codec => json_lines  # Assuming your Spring Boot logs are in JSON format
    }
}

filter {
    # Example filter to parse JSON logs and extract additional fields
    if [message] {
        json {
            source => "message"
            target => "parsed_message"
            # Remove the original message field if it's no longer needed
            remove_field => ["message"]
        }
    }

    # Optionally, move parsed fields to the top level for easier querying
    if [parsed_message] {
        mutate {
            add_field => {
                "timestamp" => "%{[parsed_message][timestamp]}"
                "level" => "%{[parsed_message][level]}"
                "logger" => "%{[parsed_message][logger]}"
                "thread" => "%{[parsed_message][thread]}"
                "message" => "%{[parsed_message][message]}"
                "exception" => "%{[parsed_message][exception]}"
            }
            remove_field => ["parsed_message"]
        }
    }

    # Date filter to convert timestamp field to appropriate format
    date {
        match => ["timestamp", "yyyy-MM-dd'T'HH:mm:ss.SSS"]
        target => "@timestamp"
        remove_field => ["timestamp"]
    }
}

output {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        user => "logstash_internal"
        password => "${LOGSTASH_INTERNAL_PASSWORD}"
        ilm_enabled => true
        ilm_rollover_alias => "springboot-logs"
        ilm_pattern => "000001"
        ilm_policy => "my-log-policy"  # Define this policy in Elasticsearch if not already set up
    }

    # Optional: Send output to stdout for debugging
    stdout {
        codec => rubydebug
    }
}
